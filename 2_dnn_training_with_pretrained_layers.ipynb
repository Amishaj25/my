{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e458d0-eeb7-47fc-8397-2b4133d9db6f",
   "metadata": {},
   "source": [
    "# Training Deep Neural Networks with Pretrained Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b66544-447e-4368-9d19-1b9fd6528772",
   "metadata": {},
   "source": [
    "_**Experiment on Fashion MNIST or any other appropriate dataset to check if reusing pretrained layers in transfer learning makes the training possible with less data and saves training time. Also check for any model performance improvement.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231683f2-d3b4-457f-b392-a01108994cb3",
   "metadata": {},
   "source": [
    "First a model will be trained on set A (for classification task with 8 classes such as trousers, dresses, coats, sandals, shirts, sneakers, bags, and ankle boots in Fashion MNIST dataset). Then the learning will be reused for another a binary classification task on set B (the remaining 2 classes such as T-shirts/tops and pullovers in the same dataset) since classes in set A are somewhat similar to classes in set B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53479574-53f9-4e32-b96a-9ade44a7e4e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports required packages\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc13f0b-5aa0-4bd8-90cb-486726ab4497",
   "metadata": {},
   "source": [
    "## Retrieving & Analysing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21be3482-802f-4585-ba88-6e71f0ac4252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Fashion MNIST dataset from a pickle dump\n",
    "\n",
    "with open(\"data/fashion_mnist.pickle\", \"rb\") as f:\n",
    "    fashion = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a5a6b03-2bcd-4dfa-8845-36f7848446dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Considering dataset is organized in tuple, items are referenced as follows\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb904468-8537-407c-ac8a-7b7310bef2d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the shape of the training and test dataset\n",
    "\n",
    "print(\"Train dataset shape:\", <code here>)\n",
    "\n",
    "print(\"Test dataset shape:\", <code here>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "889aa6a0-b345-441a-b46d-d2a5a3278893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each training and test example is assigned to one of the following labels.\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \\\n",
    "               \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f7152b-40d2-44a5-8afc-8100dfc6edc3",
   "metadata": {},
   "source": [
    "## Preparing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f3cd7a4-7131-4c30-93a1-9f349d765d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizes the data between 0 and 1 for effective neural network model training\n",
    "X_train_full, X_test = X_train_full / 255., X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "908dfc4a-d5f4-4d52-9f68-76f4641ed489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splits train dataset further to seperate 5000 instances to be used as validation set\n",
    "# Also, consider stratification during splitting.\n",
    "\n",
    "X_train, X_val, y_train, y_val = <code here>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb12e04-a37e-4713-8aba-420da4b94609",
   "metadata": {},
   "source": [
    "**Splits Fashion MNIST into tasks A and B, then train and save.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "198021a2-314f-42e3-b75e-87e756186cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store class ids of the target items into variables.\n",
    "# In this case, variable pos_class_id and neg_class_id will store 2 and 0, respectively.\n",
    "# Also, item \"Pullover\" and \"T-shirt/top\" are considered as positive and negative class, respectively.\n",
    "\n",
    "pos_class_id = class_names.index(\"Pullover\")\n",
    "neg_class_id = class_names.index(\"T-shirt/top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05f00fff-4181-4135-b4c7-913a9f93a506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    \"\"\"\n",
    "    Splits the dataset having all items into a pair of tuples - one for dataset for 8-class classification task\n",
    "    and other one for dataset for the remaining 2-class classification task.\n",
    "    \"\"\"\n",
    "    y_for_B = (y == pos_class_id) | (y == neg_class_id)\n",
    "    y_A = y[~y_for_B]\n",
    "    y_B = (y[y_for_B] == pos_class_id).astype(np.float32)\n",
    "    old_class_ids = list(set(range(10)) - set([neg_class_id, pos_class_id]))\n",
    "    for old_class_id, new_class_id in zip(old_class_ids, range(8)):\n",
    "        y_A[y_A == old_class_id] = new_class_id  # reorder class ids for A\n",
    "        \n",
    "    return ((X[~y_for_B], y_A), (X[y_for_B], y_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5461b2bd-2b28-4c93-98af-057b105b6f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splits train, validation and test data into respective dataset for classification task A and B\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_val_A, y_val_A), (X_val_B, y_val_B) = split_dataset(X_val, y_val)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "\n",
    "# Considers only 200 instances for training for classification task B\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9045d0c-bd12-4033-ae84-fb533306f244",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2903a952-c1c1-4f78-9938-1badf74ca16e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dense nueral network for classification task A\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_A = tf.keras.Sequential([\n",
    "    # Initialize a \"Flatten\" layer with input shape\n",
    "    <code here>,\n",
    "    \n",
    "    # Initialize three \"Dense\" layers specifying each with 100 as output shape, \n",
    "    # \"relu\" as activation function and \"he_normal\" as kernel initializer\n",
    "    <code here>,\n",
    "    <code here>,\n",
    "    <code here>,\n",
    "    \n",
    "    # Initialize a \"Dense\" layer specifying 8 as output shape and activation function \n",
    "    # according to the task\n",
    "    <code here>\n",
    "])\n",
    "\n",
    "# Initialize \"SGD\" as model optimizer with 0.001 as learning rate\n",
    "optimizer = <code here>\n",
    "\n",
    "# Compile the model by specifying sparse categorical crossentropy as loss function,\n",
    "# already initialized optimizer and \"accuracy\" as a metric\n",
    "<code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc9d6bf-32da-4671-9e46-bdcb327e0867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit the model by specifying training dataset, 20 epochs and validation data (tuple with features and labels)\n",
    "history = <code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f4ab4e83-f36a-4101-b3fd-f7bd07877147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saves the model to be used later for transfer learning\n",
    "# NOTE: Make sure the folder \"models\" exists under the current working directory\n",
    "\n",
    "model_A.save(\"./models/my_fashion_mnist_model_A.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c45b8c0-8afa-4cfb-985d-cb66f1052e89",
   "metadata": {},
   "source": [
    "**Now, to realize whether if transfer learning works or not, first train model B, then evaluate it, without reusing model A.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf13b8e5-51f3-4ff2-97ed-18a4560565ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dense nueral network for classification task B\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_B = tf.keras.Sequential([\n",
    "    # Initialize a \"Flatten\" layer with input shape\n",
    "    <code here>,\n",
    "    \n",
    "    # Initialize three \"Dense\" layers specifying each with 100 as output shape, \n",
    "    # \"relu\" as activation function and \"he_normal\" as kernel initializer\n",
    "    <code here>,\n",
    "    <code here>,\n",
    "    <code here>,\n",
    "    \n",
    "    # Initialize a \"Dense\" layer specifying output shape and activation function\n",
    "    # appropriate for binary classification task\n",
    "    <code here>\n",
    "])\n",
    "\n",
    "# Initialize \"SGD\" as model optimizer with 0.001 as learning rate\n",
    "optimizer = <code here>\n",
    "\n",
    "# Compile the model by specifying binary crossentropy as loss function,\n",
    "# already initialized optimizer and \"accuracy\" as a metric\n",
    "<code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1630dfd8-83f4-419a-bacc-5fa82f952be4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit the model by specifying training dataset, 20 epochs and validation data (tuple with features and labels)\n",
    "history = model_B.fit(X_train_B, y_train_B, epochs=20, validation_data=(X_val_B, y_val_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c680e5-e1e4-4b3a-b622-19ae359de421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on test dataset\n",
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a102c1-7989-4cdf-9d72-cd09b9c89493",
   "metadata": {},
   "source": [
    "**Note down Model B's accuracy on the test set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c9b740-74cb-4535-93d2-f4beccc3076d",
   "metadata": {},
   "source": [
    "**Now let's try reusing the pretrained model A.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9d79bd98-5b33-4444-8057-b7a18f316032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the model trained for classification task A\n",
    "model_A = tf.keras.models.load_model(\"./models/my_fashion_mnist_model_A.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "be0f8c02-de3b-4fd8-9524-49201c8f80dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# Clone network architecture of model A into a new model\n",
    "model_A_clone = tf.keras.models.clone_model(model_A)\n",
    "\n",
    "# Copy model A's learned weights into the cloned model\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d886bf8-57dc-4b99-b070-a0aa559a9273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create target model B cloning all layers, except for the output layer\n",
    "model_B_on_A = tf.keras.Sequential(model_A_clone.layers[:-1])\n",
    "\n",
    "# Then initialize a \"Dense\" layer a one-node output and sigmoid activation function, and\n",
    "# and add to target model B\n",
    "model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fe40df-1152-4a02-8195-dbae064b82da",
   "metadata": {},
   "source": [
    "**Target model's training takes place into two phases. In the first phase, only output layer gets trained over a shorter iterations keeping all hidden layers non-trainable, and in the second phase, all layers are trained over a relatively longer iterations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b51bbea-ef3c-407a-9ad7-08be854768a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Freeze all the hidden layers before training\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75bb9df-22ff-46cd-92fc-ba71f9c2b586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fits the model over a shorter iteration (e.g. 4) to train only the output layer\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4, validation_data=(X_val_B, y_val_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9216bbf9-5944-48bd-8b8a-3d3a5749885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then allows hidden layers trainable before next iterations of training\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e2d84-f381-4eb2-b4cb-c080940f4e28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fits the full model.\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16, validation_data=(X_val_B, y_val_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df68d2-66fa-4714-8db1-78f8ee5de6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Once again, evaluates the model B against test dataset\n",
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018288ca-cb5b-43e1-9fa6-5582c9f54db5",
   "metadata": {},
   "source": [
    "**Note down the accuracy of the new model B which was built over pretrained layer, and compare accuracy between these two models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dde077-be64-49ff-9d04-28c03282c79c",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "Note down all your observations in green/blue book."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
